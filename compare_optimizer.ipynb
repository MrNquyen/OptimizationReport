{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "6TExzWGfu73P"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **IMPORT**"
      ],
      "metadata": {
        "id": "NS5rhzOlu0k9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "ok4--7gSuzJN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Subset, random_split\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score, accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **FUNCTIONS**"
      ],
      "metadata": {
        "id": "BL0JkLxCvaPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_json(path, content):\n",
        "    with open(path, \"w\", encoding=\"utf-8\") as file:\n",
        "        json.dump(content, file, ensure_ascii=False, indent=3)\n"
      ],
      "metadata": {
        "id": "e_GLP43SvcNR"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LOAD DATA**"
      ],
      "metadata": {
        "id": "yv6sf_i1u4Wp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Load CIFAR10***"
      ],
      "metadata": {
        "id": "M0yoXf7RwV86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 128"
      ],
      "metadata": {
        "id": "RHM2kdLCe7Bg"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
        "                         (0.2470, 0.2435, 0.2616))\n",
        "])\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
        "                         (0.2470, 0.2435, 0.2616))\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform_train)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform_test)\n"
      ],
      "metadata": {
        "id": "DFiOWxUEu7lZ"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Train - Dev - Test***"
      ],
      "metadata": {
        "id": "Jl8JY8eCwYoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.8 * len(train_dataset))\n",
        "dev_size = len(train_dataset) - train_size"
      ],
      "metadata": {
        "id": "li4TWKDcwdjK"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, dev_dataset= random_split(train_dataset, [train_size, dev_size])"
      ],
      "metadata": {
        "id": "Gx12T6v9Vo3w"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader_fullset = DataLoader(train_dataset, batch_size=len(train_dataset), shuffle=False, num_workers=2)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "dev_loader = DataLoader(dev_dataset, batch_size=100, shuffle=False, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=100, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "WTIlEC3DV4Ar"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BUILD MODEL**"
      ],
      "metadata": {
        "id": "6TExzWGfu73P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Build Model***"
      ],
      "metadata": {
        "id": "c2WYhXsevhCq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    \"\"\"\n",
        "    Một mô hình CNN cơ bản cho bài toán Image Classification.\n",
        "    Cấu trúc:\n",
        "      - 3 khối convolution + batchnorm + relu + maxpool\n",
        "      - 2 tầng fully-connected để phân loại\n",
        "    \"\"\"\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "\n",
        "        # Block 1: Conv -> BN -> ReLU -> MaxPool\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        # Block 2\n",
        "        self.block2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "\n",
        "        # Block 3\n",
        "        self.block3 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "\n",
        "        # Fully Connected Layers\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128 * 4 * 4, 256),  # CIFAR-10 có input 32x32 → sau 3 lần pool còn 4x4\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "67adVy1DvkmC"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Optimizer***"
      ],
      "metadata": {
        "id": "FgvxOdjYWZKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 30\n",
        "LR = 1e-4"
      ],
      "metadata": {
        "id": "2C9iz0dJfD94"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizers_list = {\n",
        "    \"GD\": (optim.SGD, {\"lr\": LR}), # Gradient Descent\n",
        "    \"SGD\": (optim.SGD, {\"lr\": LR}), # Schocastic Gradient Descent\n",
        "    \"AdaGrad\": (optim.Adagrad, {\"lr\": LR}), # AdaGrad\n",
        "    \"Adam\": (optim.Adam, {\"lr\": LR}) # Adam\n",
        "}"
      ],
      "metadata": {
        "id": "PVYcNZbWWdq3"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TRAINING**"
      ],
      "metadata": {
        "id": "HkxS7yQMu-qt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Trainer Class***"
      ],
      "metadata": {
        "id": "FJcs5X6YvAgt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer:\n",
        "    def __init__(self, optimizer_name, optimizer_cls, optimizer_params, epochs, save_dir) -> None:\n",
        "        self.epochs = epochs\n",
        "        self.save_dir = save_dir\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.optimizer_name = optimizer_name\n",
        "        self.optimizer_cls = optimizer_cls\n",
        "        self.optimizer_params = optimizer_params\n",
        "\n",
        "        self.load()\n",
        "\n",
        "    #-- Load\n",
        "    def load(self):\n",
        "        self.load_model()\n",
        "        self.load_optimizer()\n",
        "        self.load_loss_fn()\n",
        "        self.load_ckpt()\n",
        "\n",
        "    def load_model(self):\n",
        "        self.model = SimpleCNN()\n",
        "        self.model = self.model.to(self.device)\n",
        "\n",
        "    def load_optimizer(self):\n",
        "        self.optimizer = self.optimizer_cls(self.model.parameters(), **self.optimizer_params)\n",
        "\n",
        "    def load_loss_fn(self):\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    #-- Training\n",
        "    def train(\n",
        "            self,\n",
        "            train_loader,\n",
        "            val_loader\n",
        "        ):\n",
        "        train_losses = []\n",
        "        val_losses = []\n",
        "        epoch_val_logs = {}\n",
        "\n",
        "        best_f1 = -1000\n",
        "\n",
        "        pbar = tqdm(range(self.epochs), desc=\"Training Process ...\")\n",
        "        for epoch in pbar:\n",
        "            #~ Training\n",
        "            self.model.train()\n",
        "            for inputs, targets in train_loader:\n",
        "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
        "                self.optimizer.zero_grad()\n",
        "                outputs = self.model(inputs)\n",
        "                loss = self.criterion(outputs, targets)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                loss_scalar = loss.detach().cpu().item()\n",
        "                train_losses.append(loss_scalar)\n",
        "\n",
        "            #~ Validation\n",
        "            self.model.eval()\n",
        "            all_predicts = []\n",
        "            all_targets = []\n",
        "            with torch.no_grad():\n",
        "                for inputs, targets in val_loader:\n",
        "                    inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
        "                    outputs = self.model(inputs)\n",
        "                    _, predicts = torch.max(outputs, 1)\n",
        "\n",
        "                    #~ Save inferences\n",
        "                    all_predicts.extend(predicts.cpu().numpy())\n",
        "                    all_targets.extend(targets.cpu().numpy())\n",
        "\n",
        "                    #~ Calculate Loss\n",
        "                    loss = self.criterion(outputs, targets)\n",
        "                    loss_scalar = loss.detach().cpu().item()\n",
        "                    val_losses.append(loss_scalar)\n",
        "\n",
        "            val_acc = accuracy_score(all_targets, all_predicts)\n",
        "            val_f1_macro = f1_score(all_targets, all_predicts, average='macro')\n",
        "            val_f1_weighted = f1_score(all_targets, all_predicts, average='weighted')\n",
        "\n",
        "            if val_f1_macro > best_f1:\n",
        "                self.save_checkpoint()\n",
        "\n",
        "            #~ Save Log\n",
        "            train_loss_avg = sum(train_losses) / len(train_losses),\n",
        "            val_loss_avg = sum(val_losses) / len(val_losses)\n",
        "\n",
        "            epoch_log = {\n",
        "                \"train_loss\": f\"{train_loss_avg}\",\n",
        "                \"val_loss\": f\"{val_loss_avg}\",\n",
        "                \"val_acc\": val_acc,\n",
        "                \"val_f1_macro\": val_f1_macro,\n",
        "                \"val_f1_weighted\": val_f1_weighted\n",
        "            }\n",
        "            pbar.set_postfix(epoch_log)\n",
        "            epoch_val_logs[epoch] = epoch_log\n",
        "\n",
        "        return epoch_val_logs\n",
        "\n",
        "\n",
        "    def inference(self, test_loader):\n",
        "        all_predicts = []\n",
        "        all_targets = []\n",
        "        test_losses = []\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in tqdm(test_loader, desc=\"Inferencing\"):\n",
        "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
        "                outputs = self.model(inputs)\n",
        "                _, predicts = torch.max(outputs, 1)\n",
        "\n",
        "                #~ Save inferences\n",
        "                all_predicts.extend(predicts.cpu().numpy())\n",
        "                all_targets.extend(targets.cpu().numpy())\n",
        "\n",
        "                #~ Calculate Loss\n",
        "                loss = self.criterion(outputs, targets)\n",
        "                loss_scalar = loss.detach().cpu().item()\n",
        "                test_losses.append(loss_scalar)\n",
        "\n",
        "            test_loss_avg = sum(test_losses) / len(test_losses)\n",
        "            test_acc = accuracy_score(all_targets, all_predicts)\n",
        "            test_f1_macro = f1_score(all_targets, all_predicts, average='macro')\n",
        "            test_f1_weighted = f1_score(all_targets, all_predicts, average='weighted')\n",
        "            return {\n",
        "                \"test_loss\": test_loss_avg,\n",
        "                \"test_acc\": test_acc,\n",
        "                \"test_f1_macro\": test_f1_macro,\n",
        "                \"test_f1_weighted\": test_f1_weighted\n",
        "            }\n",
        "\n",
        "\n",
        "    #-- Save Model\n",
        "    def save_checkpoint(self):\n",
        "        checkpoint_path = os.path.join(self.save_dir, f\"cnn_model_checkpoint_{self.optimizer_name}_best.pt\")\n",
        "        torch.save({\n",
        "            \"model_state_dict\": self.model.state_dict(),\n",
        "            \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
        "        }, checkpoint_path)\n",
        "        print(f\"\\n\\n✅ Model checkpoint saved to: {checkpoint_path}\")\n",
        "\n",
        "\n",
        "    def load_ckpt(self):\n",
        "        checkpoint_path = os.path.join(self.save_dir, f\"cnn_model_checkpoint_{self.optimizer_name}_best.pt\")\n",
        "        if not os.path.exists(checkpoint_path):\n",
        "            print(f\"✅ No {checkpoint_path} founded\")\n",
        "            return\n",
        "\n",
        "        # Tạo model và optimizer\n",
        "        self.model = self.model.to(self.device)\n",
        "        self.optimizer = self.optimizer_cls(self.model.parameters(), **self.optimizer_params)\n",
        "\n",
        "        # Load checkpoint\n",
        "        checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
        "        self.model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "        self.optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "\n",
        "        self.model.eval()  # đặt model sang evaluation mode\n",
        "        print(f\"✅ Model loaded from {checkpoint_path}\")\n",
        "\n",
        "\n",
        "\n",
        "    #-- Get Model\n",
        "    def get_model(self):\n",
        "        return self.model"
      ],
      "metadata": {
        "id": "-3JG3kwYd2Ab"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizers_list = {\n",
        "    \"GD\": (optim.SGD, {\"lr\": LR}), # Gradient Descent\n",
        "    \"SGD\": (optim.SGD, {\"lr\": LR}), # Schocastic Gradient Descent\n",
        "    \"AdaGrad\": (optim.Adagrad, {\"lr\": LR}), # AdaGrad\n",
        "    \"Adam\": (optim.Adam, {\"lr\": LR}) # Adam\n",
        "}"
      ],
      "metadata": {
        "id": "xFssnO_c216C"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Training GD***"
      ],
      "metadata": {
        "id": "w_Mnku7CvKph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gd_trainer = Trainer(\n",
        "    optimizer_name=\"GD\",\n",
        "    optimizer_cls=optimizers_list[\"GD\"][0],\n",
        "    optimizer_params=optimizers_list[\"GD\"][1],\n",
        "    epochs=EPOCHS,\n",
        "    save_dir=\"/content/drive/MyDrive/QUÝNHEA/Project/models\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krRK_HNJvZpK",
        "outputId": "196050ee-e1a6-4707-8750-623fbf04e92c"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ No /content/drive/MyDrive/QUÝNHEA/Project/models/cnn_model_checkpoint_GD_best.pt founded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gd_logs = gd_trainer.train(train_loader_fullset, dev_loader)"
      ],
      "metadata": {
        "id": "Y66KI3OWyLTE"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Training SGD***"
      ],
      "metadata": {
        "id": "F62AW30l2x4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sgd_trainer = Trainer(\n",
        "    optimizer_name=\"SGD\",\n",
        "    optimizer_cls=optimizers_list[\"SGD\"][0],\n",
        "    optimizer_params=optimizers_list[\"SGD\"][1],\n",
        "    epochs=EPOCHS,\n",
        "    save_dir=\"/content/drive/MyDrive/QUÝNHEA/Project/models\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaEOczXq2x4t",
        "outputId": "036e48d6-c8d4-4e23-9c66-54384c26f398"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model loaded from /content/drive/MyDrive/QUÝNHEA/Project/models/cnn_model_checkpoint_SGD_best.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sgd_logs = sgd_trainer.train(train_loader, dev_loader)"
      ],
      "metadata": {
        "id": "GU-lCbqv2x4u"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sgd_save_path = os.path.join(\"/content/drive/MyDrive/QUÝNHEA/Project/models\", \"sgd_log.json\")\n",
        "# save_json(sgd_save_path, sgd_logs)"
      ],
      "metadata": {
        "id": "He2pYgInDlaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sgd_logs = sgd_trainer.inference(test_loader)\n",
        "test_sgd_save_path = os.path.join(\"/content/drive/MyDrive/QUÝNHEA/Project/models\", \"test_sgd_log.json\")\n",
        "save_json(test_sgd_save_path, test_sgd_logs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_P1t3T6MEZwj",
        "outputId": "629b1a68-5e91-4b10-bde7-68d5e4727a9a"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing: 100%|██████████| 100/100 [00:02<00:00, 45.12it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_sgd_logs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysDm81PzFcUC",
        "outputId": "ccd62f6c-e6e1-48f8-e079-1f7f62774f7b"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test_loss': 1.8440232408046722,\n",
              " 'test_acc': 0.3657,\n",
              " 'test_f1_macro': 0.3566435823626392,\n",
              " 'test_f1_weighted': 0.3566435823626392}"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Training Adam***"
      ],
      "metadata": {
        "id": "0pn4SyguvUke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adam_trainer = Trainer(\n",
        "    optimizer_name=\"Adam\",\n",
        "    optimizer_cls=optimizers_list[\"Adam\"][0],\n",
        "    optimizer_params=optimizers_list[\"Adam\"][1],\n",
        "    epochs=EPOCHS,\n",
        "    save_dir=\"/content/drive/MyDrive/QUÝNHEA/Project/models\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgpC57jWvZHI",
        "outputId": "08352498-d6fd-4649-b591-d9b0f1fa9afd"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model loaded from /content/drive/MyDrive/QUÝNHEA/Project/models/cnn_model_checkpoint_Adam_best.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# adam_logs = adam_trainer.train(train_loader, dev_loader)"
      ],
      "metadata": {
        "id": "yDw_IclQ5oMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adam_save_path = os.path.join(\"/content/drive/MyDrive/QUÝNHEA/Project/models\", \"adam_log.json\")\n",
        "# save_json(adam_save_path, adam_logs)"
      ],
      "metadata": {
        "id": "dK2xcnY5ENyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_adam_logs = adam_trainer.inference(test_loader)\n",
        "test_adam_save_path = os.path.join(\"/content/drive/MyDrive/QUÝNHEA/Project/models\", \"test_adam_log.json\")\n",
        "save_json(test_adam_save_path, test_adam_logs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDSN8NtqHoSA",
        "outputId": "547fe4c8-4cce-467f-f8a4-61d2561ae1e0"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing: 100%|██████████| 100/100 [00:04<00:00, 21.38it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_adam_logs"
      ],
      "metadata": {
        "id": "81StZMb8HwQq",
        "outputId": "ed709614-f229-4eac-9fdd-bc4a14d7b02a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test_loss': 0.6607854717969894,\n",
              " 'test_acc': 0.7686,\n",
              " 'test_f1_macro': 0.7666959863863341,\n",
              " 'test_f1_weighted': 0.7666959863863342}"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Training AdaGrad***"
      ],
      "metadata": {
        "id": "Gopngg3hvWfV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adaGrad_trainer = Trainer(\n",
        "    optimizer_name=\"AdaGrad\",\n",
        "    optimizer_cls=optimizers_list[\"AdaGrad\"][0],\n",
        "    optimizer_params=optimizers_list[\"AdaGrad\"][1],\n",
        "    epochs=EPOCHS,\n",
        "    save_dir=\"/content/drive/MyDrive/QUÝNHEA/Project/models\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daIvbY5bvSq4",
        "outputId": "c43cf503-e1cd-4282-8384-de5f1914a989"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model loaded from /content/drive/MyDrive/QUÝNHEA/Project/models/cnn_model_checkpoint_AdaGrad_best.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adaGrad_logs = adaGrad_trainer.train(train_loader, dev_loader)"
      ],
      "metadata": {
        "id": "enzEqBNJ51An"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adaGrad_save_path = os.path.join(\"/content/drive/MyDrive/QUÝNHEA/Project/models\", \"adaGrad_log.json\")\n",
        "save_json(adaGrad_save_path, adaGrad_logs)"
      ],
      "metadata": {
        "id": "VPiSy2d4ERq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_adaGrad_logs = adaGrad_trainer.inference(test_loader)\n",
        "test_adaGrad_save_path = os.path.join(\"/content/drive/MyDrive/QUÝNHEA/Project/models\", \"test_adaGrad_log.json\")\n",
        "save_json(test_adaGrad_save_path, test_adaGrad_logs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJ420CvVHrom",
        "outputId": "626ea52d-0116-4205-ee2b-7b9a0b57a5d8"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Inferencing: 100%|██████████| 100/100 [00:04<00:00, 20.31it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_adaGrad_logs"
      ],
      "metadata": {
        "id": "5w02euzPHyXX",
        "outputId": "981ae5e6-9cf8-4d6b-8881-6623c98f0de0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test_loss': 1.4940692114830016,\n",
              " 'test_acc': 0.4732,\n",
              " 'test_f1_macro': 0.46892948540150964,\n",
              " 'test_f1_weighted': 0.46892948540150975}"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EVALUATE**"
      ],
      "metadata": {
        "id": "Rzxv-fv5vBOP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rsjLQEm0vDMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EDA**"
      ],
      "metadata": {
        "id": "7Oa2IyxwvDkf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u4HHPzqSvNWT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}